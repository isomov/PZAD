{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# boosters.pro/championship/digital_reputation_challenge\n",
    "# pub: 0.612335\n",
    "# priv: 0.612814\n",
    "# 19 PLACE ðŸ¥ˆ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "from scipy import sparse, stats\n",
    "from scipy.linalg import svd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.model_selection import (KFold, StratifiedKFold, cross_val_score,\n",
    "                                     cross_validate, train_test_split, cross_val_predict)\n",
    "from tqdm import tqdm\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "import lightgbm as lgb\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import implicit\n",
    "from scipy.sparse import csr_matrix\n",
    "import umap\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_score_statement(estimator,\n",
    "                                     X,\n",
    "                                     y,\n",
    "                                     scoring,\n",
    "                                     n_splits=5,\n",
    "                                     statement=None,\n",
    "                                     random_state=0):\n",
    "    cv = StratifiedKFold(n_splits=n_splits,\n",
    "                             shuffle=True,\n",
    "                             random_state=random_state)\n",
    "    cv_iter = list(cv.split(X, y))\n",
    "    scores = []\n",
    "\n",
    "    for train, test in cv_iter:\n",
    "        estimator.fit(X.iloc[train, :].values, y.iloc[train].values)\n",
    "        if statement is not None:\n",
    "            y_statement = y.iloc[test].loc[statement[test]]\n",
    "            pred_statement = estimator.predict_proba(\n",
    "                X.iloc[test, :].loc[statement[test]].values)[:, 1]\n",
    "        else:\n",
    "            y_statement = y.iloc[test]\n",
    "            pred_statement = estimator.predict_proba(X.iloc[test, :].values)[:, 1]\n",
    "        scores.append(scoring(y_statement, pred_statement))\n",
    "    return np.array(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xgb(X, Y): \n",
    "    res_ = []\n",
    "    n_estimators = [100, 200, 250]\n",
    "    min_child = [2,3,4,5]\n",
    "    max_depth = [2,3]\n",
    "    lr = [0.017, 0.009, 0.005, 0.02, 0.1]\n",
    "    for e in n_estimators:\n",
    "        for md in max_depth:\n",
    "            for mcw in min_child:\n",
    "                for l in lr:\n",
    "                    print(e, md, mcw, l)\n",
    "                    res = cross_validation_score_statement(XGBClassifier(n_jobs=8, random_state=0, learning_rate=l, min_child_weight=mcw, max_depth=md, n_estimators=e),\n",
    "                                             X.drop(columns=['id']),\n",
    "                                             Y,\n",
    "                                             roc_auc_score,\n",
    "                                             n_splits=3,\n",
    "                                             statement=None,\n",
    "                                             random_state=0)\n",
    "                    print(res.mean())\n",
    "                    res_.append(((e, md, mcw, l), res.mean(), res))\n",
    "    return sorted(res_, key=lambda x: x[1])[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stack_preds(estim, X, target, n_splits):\n",
    "    return cross_val_predict(estim, X, target, cv=n_splits, n_jobs=8, method='predict_proba')[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = 'train/'\n",
    "X1 = pd.read_csv(TRAIN_PATH + 'X1.csv')\n",
    "X2 = pd.read_csv(TRAIN_PATH + 'X2.csv')\n",
    "X3 = pd.read_csv(TRAIN_PATH + 'X3.csv')\n",
    "\n",
    "Y = pd.read_csv(TRAIN_PATH + 'Y.csv')\n",
    "\n",
    "TEST_PATH = 'test/'\n",
    "\n",
    "X1_test = pd.read_csv(TEST_PATH + 'X1.csv')\n",
    "X2_test = pd.read_csv(TEST_PATH + 'X2.csv')\n",
    "X3_test = pd.read_csv(TEST_PATH + 'X3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20 and 10 factors from ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "k=20\n",
    "\n",
    "model = implicit.als.AlternatingLeastSquares(factors=k, iterations=20, calculate_training_loss=True, regularization=1)\n",
    "X2_ = X2.append(X2_test).sort_values('id')\n",
    "res = csr_matrix((np.ones(len(X2_)), (X2_['id'], X2_['A'])))\n",
    "model.fit(res)\n",
    "fac = pd.DataFrame(model.item_factors[X1['id']], columns=list(range(26, 26 + k)))\n",
    "fac_test = pd.DataFrame(model.item_factors[X1_test['id']], columns=list(range(26, 26 + k)))\n",
    "fac['id'] = X1['id']\n",
    "fac_test['id'] = X1_test['id']\n",
    "X = X1.merge(fac, on='id').drop(columns=['19'])\n",
    "X_test = X1_test.merge(fac_test, on='id').drop(columns=['19'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "k=10\n",
    "\n",
    "model = implicit.als.AlternatingLeastSquares(factors=k, iterations=20, calculate_training_loss=True, regularization=1)\n",
    "X2_ = X2.append(X2_test).sort_values('id')\n",
    "res = csr_matrix((np.ones(len(X2_)), (X2_['id'], X2_['A'])))\n",
    "model.fit(res)\n",
    "fac = pd.DataFrame(model.item_factors[X1['id']], columns=list(range(26, 26 + k)))\n",
    "fac_test = pd.DataFrame(model.item_factors[X1_test['id']], columns=list(range(26, 26 + k)))\n",
    "fac['id'] = X1['id']\n",
    "fac_test['id'] = X1_test['id']\n",
    "X_ = X1.merge(fac, on='id').drop(columns=['19'])\n",
    "X_test_ = X1_test.merge(fac_test, on='id').drop(columns=['19'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estims_data = [('xgb_1', XGBClassifier(learning_rate=0.02, max_depth=3, min_child_weight=5, n_estimators=100, random_state=0), X, X_test),\n",
    "              ('lr_1', LogisticRegression(C=3, class_weight='balanced'), (X - X.mean()) / X.std(), (X_test- X.mean()) / X.std()),\n",
    "              ('rf_1', RandomForestClassifier(n_estimators=300, criterion='entropy', max_depth=3, random_state=0), X, X_test),\n",
    "               ('svm_r', SVC(C=3, class_weight='balanced', probability=True, random_state=0), (X - X.mean()) / X.std(), (X_test- X.mean()) / X.std()),\n",
    "               ('nn_l', MLPClassifier((200, 100,), solver='sgd'), (X - X.mean()) / X.std(), (X_test- X.mean()) / X.std()),\n",
    "                ('xgb_2', XGBClassifier(learning_rate=0.02, max_depth=2, min_child_weight=5, n_estimators=250, random_state=0), X_, X_test_),\n",
    "              ('lr_2', LogisticRegression(C=3, class_weight='balanced'), (X_ - X_.mean()) / X_.std(), (X_test_- X_.mean()) / X_.std()),\n",
    "              ('rf_2', RandomForestClassifier(n_estimators=200, criterion='entropy', max_depth=3, random_state=0), X_, X_test_),\n",
    "               ('svm_r_2', SVC(C=3, class_weight='balanced', probability=True, random_state=0), (X_ - X_.mean()) / X_.std(), (X_test_- X_.mean()) / X_.std()),\n",
    "               ('nn_2', MLPClassifier((200, 100,), solver='sgd'), (X_ - X_.mean()) / X_.std(), (X_test_- X_.mean()) / X_.std()),\n",
    "              ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking for ALS features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_preds_1 = {}\n",
    "test_preds_1 = {}\n",
    "stacked_preds_2 = {}\n",
    "test_preds_2 = {}\n",
    "stacked_preds_3 = {}\n",
    "test_preds_3 = {}\n",
    "stacked_preds_4 = {}\n",
    "test_preds_4 = {}\n",
    "stacked_preds_5 = {}\n",
    "test_preds_5 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = Y['1']\n",
    "for name, estim, data_tr, data_test in estims_data:\n",
    "    print(name)\n",
    "    stacked_preds_1[name] = get_stack_preds(estim, data_tr.drop(columns=['id']), target, 10)\n",
    "    print(roc_auc_score(target, stacked_preds_1[name]))\n",
    "    estim.fit(data_tr.drop(columns=['id']), target)\n",
    "    test_preds_1[name] = estim.predict_proba(data_test.drop(columns=['id']))[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = Y['2']\n",
    "for name, estim, data_tr, data_test in estims_data:\n",
    "    print(name)\n",
    "    stacked_preds_2[name] = get_stack_preds(estim, data_tr.drop(columns=['id']), target, 10)\n",
    "    print(roc_auc_score(target, stacked_preds_2[name]))\n",
    "    estim.fit(data_tr.drop(columns=['id']), target)\n",
    "    test_preds_2[name] = estim.predict_proba(data_test.drop(columns=['id']))[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target = Y['3']\n",
    "for name, estim, data_tr, data_test in estims_data:\n",
    "    print(name)\n",
    "    stacked_preds_3[name] = get_stack_preds(estim, data_tr.drop(columns=['id']), target, 10)\n",
    "    print(roc_auc_score(target, stacked_preds_3[name]))\n",
    "    estim.fit(data_tr.drop(columns=['id']), target)\n",
    "    test_preds_3[name] = estim.predict_proba(data_test.drop(columns=['id']))[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = Y['4']\n",
    "for name, estim, data_tr, data_test in estims_data:\n",
    "    print(name)\n",
    "    stacked_preds_4[name] = get_stack_preds(estim, data_tr.drop(columns=['id']), target, 10)\n",
    "    print(roc_auc_score(target, stacked_preds_4[name]))\n",
    "    estim.fit(data_tr.drop(columns=['id']), target)\n",
    "    test_preds_4[name] = estim.predict_proba(data_test.drop(columns=['id']))[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = Y['5']\n",
    "for name, estim, data_tr, data_test in estims_data:\n",
    "    print(name)\n",
    "    stacked_preds_5[name] = get_stack_preds(estim, data_tr.drop(columns=['id']), target, 10)\n",
    "    print(roc_auc_score(target, stacked_preds_5[name]))\n",
    "    estim.fit(data_tr.drop(columns=['id']), target)\n",
    "    test_preds_5[name] = estim.predict_proba(data_test.drop(columns=['id']))[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_1 = {}\n",
    "ds_1['cl_1'] = stacked_preds_1['xgb_1']\n",
    "ds_1['cl_10'] = stacked_preds_1['xgb_2']\n",
    "ds_1['cl_3'] = stacked_preds_1['rf_1']\n",
    "ds_1['cl_5'] = stacked_preds_1['lr_1']\n",
    "ds_1['cl_8'] = stacked_preds_1['svm_r_2']\n",
    "ds_1['cl_9'] = stacked_preds_1['nn_2']\n",
    "ds_1_test = {}\n",
    "ds_1_test['cl_1'] = test_preds_1['xgb_1']\n",
    "ds_1_test['cl_10'] = test_preds_1['xgb_2']\n",
    "ds_1_test['cl_3'] = test_preds_1['rf_1']\n",
    "ds_1_test['cl_5'] = test_preds_1['lr_1']\n",
    "ds_1_test['cl_8'] = test_preds_1['svm_r_2']\n",
    "ds_1_test['cl_9'] = test_preds_1['nn_2']\n",
    "ds_1_ = pd.DataFrame(ds_1)\n",
    "ds_1_test_ = pd.DataFrame(ds_1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_1 = {}\n",
    "ds_1['cl_1'] = stacked_preds_2['xgb_1']\n",
    "ds_1['cl_2'] = stacked_preds_2['xgb_2']\n",
    "ds_1['cl_31'] = stacked_preds_2['rf_1']\n",
    "ds_1['cl_4'] = stacked_preds_2['lr_1']\n",
    "ds_1['cl_5'] = stacked_preds_2['svm_r_2']\n",
    "ds_1['cl_6'] = stacked_preds_2['nn_2']\n",
    "ds_1_test = {}\n",
    "ds_1_test['cl_1'] = test_preds_2['xgb_1']\n",
    "ds_1_test['cl_2'] = test_preds_2['xgb_2']\n",
    "ds_1_test['cl_31'] = test_preds_2['rf_1']\n",
    "ds_1_test['cl_4'] = test_preds_2['lr_1']\n",
    "ds_1_test['cl_5'] = test_preds_2['svm_r_2']\n",
    "ds_1_test['cl_6'] = test_preds_2['nn_2']\n",
    "ds_2 = pd.DataFrame(ds_1)\n",
    "ds_2_test = pd.DataFrame(ds_1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_1 = {}\n",
    "ds_1['cl_1'] = stacked_preds_3['xgb_1']\n",
    "ds_1['cl_2'] = stacked_preds_3['xgb_2']\n",
    "ds_1['cl_3'] = stacked_preds_3['rf_1']\n",
    "ds_1['cl_4'] = stacked_preds_3['lr_1']\n",
    "ds_1['cl_5'] = stacked_preds_3['svm_r_2']\n",
    "ds_1['cl_6'] = stacked_preds_3['nn_2']\n",
    "ds_1_test = {}\n",
    "ds_1_test['cl_1'] = test_preds_3['xgb_1']\n",
    "ds_1_test['cl_2'] = test_preds_3['xgb_2']\n",
    "ds_1_test['cl_3'] = test_preds_3['rf_1']\n",
    "ds_1_test['cl_4'] = test_preds_3['lr_1']\n",
    "ds_1_test['cl_5'] = test_preds_3['svm_r_2']\n",
    "ds_1_test['cl_6'] = test_preds_3['nn_2']\n",
    "ds_3 = pd.DataFrame(ds_1)\n",
    "ds_3_test = pd.DataFrame(ds_1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_1 = {}\n",
    "ds_1['cl_1'] = stacked_preds_4['xgb_1']\n",
    "ds_1['cl_2'] = stacked_preds_4['xgb_2']\n",
    "ds_1['cl_3'] = stacked_preds_4['rf_1']\n",
    "ds_1['cl_4'] = stacked_preds_4['lr_1']\n",
    "ds_1['cl_5'] = stacked_preds_4['svm_r_2']\n",
    "ds_1['cl_6'] = stacked_preds_4['nn_2']\n",
    "ds_1_test = {}\n",
    "ds_1_test['cl_1'] = test_preds_4['xgb_1']\n",
    "ds_1_test['cl_2'] = test_preds_4['xgb_2']\n",
    "ds_1_test['cl_3'] = test_preds_4['rf_1']\n",
    "ds_1_test['cl_4'] = test_preds_4['lr_1']\n",
    "ds_1_test['cl_5'] = test_preds_4['svm_r_2']\n",
    "ds_1_test['cl_6'] = test_preds_4['nn_2']\n",
    "ds_4 = pd.DataFrame(ds_1)\n",
    "ds_4_test = pd.DataFrame(ds_1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_1 = {}\n",
    "ds_1['cl_1'] = stacked_preds_5['xgb_1']\n",
    "ds_1['cl_2'] = stacked_preds_5['xgb_2']\n",
    "ds_1['cl_3'] = stacked_preds_5['rf_1']\n",
    "ds_1['cl_4'] = stacked_preds_5['lr_1']\n",
    "ds_1['cl_5'] = stacked_preds_5['svm_r_2']\n",
    "ds_1['cl_6'] = stacked_preds_5['nn_2']\n",
    "ds_1_test = {}\n",
    "ds_1_test['cl_1'] = test_preds_5['xgb_1']\n",
    "ds_1_test['cl_2'] = test_preds_5['xgb_2']\n",
    "ds_1_test['cl_3'] = test_preds_5['rf_1']\n",
    "ds_1_test['cl_4'] = test_preds_5['lr_1']\n",
    "ds_1_test['cl_5'] = test_preds_5['svm_r_2']\n",
    "ds_1_test['cl_6'] = test_preds_5['nn_2']\n",
    "ds_5 = pd.DataFrame(ds_1)\n",
    "ds_5_test = pd.DataFrame(ds_1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_1_['id'] = X1.id\n",
    "ds_2['id'] = X1.id\n",
    "ds_3['id'] = X1.id\n",
    "ds_4['id'] = X1.id\n",
    "ds_5['id'] = X1.id\n",
    "\n",
    "ds_1_test_['id'] = X1_test.id\n",
    "ds_2_test['id'] = X1_test.id\n",
    "ds_3_test['id'] = X1_test.id\n",
    "ds_4_test['id'] = X1_test.id\n",
    "ds_5_test['id'] = X1_test.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ustacked_preds_1 = {}\n",
    "utest_preds_1 = {}\n",
    "ustacked_preds_2 = {}\n",
    "utest_preds_2 = {}\n",
    "ustacked_preds_3 = {}\n",
    "utest_preds_3 = {}\n",
    "ustacked_preds_4 = {}\n",
    "utest_preds_4 = {}\n",
    "ustacked_preds_5 = {}\n",
    "utest_preds_5 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_ = umap.UMAP(n_components=10, random_state=0, verbose=True, metric='cosine')\n",
    "X2_ = X2.append(X2_test).sort_values('id')\n",
    "res = csr_matrix((np.ones(len(X2_)), (X2_['id'], X2_['A'])))\n",
    "fac_umap = umap_.fit_transform(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "fac_u = pd.DataFrame(fac_umap[X1['id']], columns=list(range(26, 26 + k)))\n",
    "fac_u_test = pd.DataFrame(fac_umap[X1_test['id']], columns=list(range(26, 26 + k)))\n",
    "fac_u['id'] = X1['id']\n",
    "fac_u_test['id'] = X1_test['id']\n",
    "UX = X1.merge(fac_u, on='id').drop(columns=['19'])\n",
    "UX_test = X1_test.merge(fac_u_test, on='id').drop(columns=['19'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking for UMAP features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estims_data = [('xgb_1', XGBClassifier(learning_rate=0.009, max_depth=2, min_child_weight=5, n_estimators=250, random_state=0), UX, UX_test),\n",
    "               ('lgbm_1', lgb.LGBMClassifier(n_estimators=200, class_weight='balanced'), (UX - UX.mean()) / UX.std(), (UX_test- UX.mean()) / UX.std()),\n",
    "              ('lr_1', LogisticRegression(C=3, class_weight='balanced'), (UX - UX.mean()) / UX.std(), (UX_test- UX.mean()) / UX.std()),\n",
    "              ('rf_1', RandomForestClassifier(n_estimators=300, criterion='entropy', max_depth=3, random_state=0), UX, UX_test),\n",
    "               ('svm_r', SVC(C=3, class_weight='balanced', probability=True, random_state=0), (UX - UX.mean()) / UX.std(), (UX_test- UX.mean()) / UX.std()),\n",
    "               ('nn', MLPClassifier((200, 100,), solver='sgd'), (UX - UX.mean()) / UX.std(), (UX_test- UX.mean()) / UX.std())\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estims_data = [('xgb_1', XGBClassifier(learning_rate=0.02, max_depth=2, min_child_weight=5, n_estimators=200, random_state=0), UX, UX_test),\n",
    "              ('lr_1', LogisticRegression(C=3, class_weight='balanced'), (UX - UX.mean()) / UX.std(), (UX_test- UX.mean()) / UX.std()),\n",
    "              ('rf_1', RandomForestClassifier(n_estimators=300, criterion='entropy', max_depth=3, random_state=0), UX, UX_test),\n",
    "               ('svm_r', SVC(C=3, class_weight='balanced', probability=True, random_state=0), (UX - UX.mean()) / UX.std(), (UX_test- UX.mean()) / UX.std()),\n",
    "               ('svm_l', MLPClassifier((200, 100,), solver='sgd'), (UX - UX.mean()) / UX.std(), (UX_test- UX.mean()) / UX.std())\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estims_data = [('xgb_1', XGBClassifier(learning_rate=0.005, max_depth=2, min_child_weight=3, n_estimators=250, random_state=0), UX, UX_test),\n",
    "              ('lr_1', LogisticRegression(C=3, class_weight='balanced'), (UX - UX.mean()) / UX.std(), (UX_test- UX.mean()) / UX.std()),\n",
    "              ('rf_1', RandomForestClassifier(n_estimators=300, criterion='entropy', max_depth=3, random_state=0), UX, UX_test),\n",
    "              ('svm_r', SVC(C=3, class_weight='balanced', probability=True, random_state=0), (UX - UX.mean()) / UX.std(), (UX_test- UX.mean()) / UX.std()),\n",
    "              ('nn', MLPClassifier((200, 100,), solver='sgd'), (UX - UX.mean()) / UX.std(), (UX_test- UX.mean()) / UX.std()),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = Y['1']\n",
    "for name, estim, data_tr, data_test in estims_data:\n",
    "    print(name)\n",
    "    ustacked_preds_1[name] = get_stack_preds(estim, data_tr.drop(columns=['id']), target, 10)\n",
    "    print(roc_auc_score(target, ustacked_preds_1[name]))\n",
    "    estim.fit(data_tr.drop(columns=['id']), target)\n",
    "    utest_preds_1[name] = estim.predict_proba(data_test.drop(columns=['id']))[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = Y['2']\n",
    "for name, estim, data_tr, data_test in estims_data:\n",
    "    print(name)\n",
    "    ustacked_preds_2[name] = get_stack_preds(estim, data_tr.drop(columns=['id']), target, 10)\n",
    "    print(roc_auc_score(target, ustacked_preds_2[name]))\n",
    "    estim.fit(data_tr.drop(columns=['id']), target)\n",
    "    utest_preds_2[name] = estim.predict_proba(data_test.drop(columns=['id']))[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = Y['3']\n",
    "for name, estim, data_tr, data_test in estims_data:\n",
    "    print(name)\n",
    "    ustacked_preds_3[name] = get_stack_preds(estim, data_tr.drop(columns=['id']), target, 10)\n",
    "    print(roc_auc_score(target, ustacked_preds_3[name]))\n",
    "    estim.fit(data_tr.drop(columns=['id']), target)\n",
    "    utest_preds_3[name] = estim.predict_proba(data_test.drop(columns=['id']))[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = Y['4']\n",
    "for name, estim, data_tr, data_test in estims_data:\n",
    "    print(name)\n",
    "    ustacked_preds_4[name] = get_stack_preds(estim, data_tr.drop(columns=['id']), target, 10)\n",
    "    print(roc_auc_score(target, ustacked_preds_4[name]))\n",
    "    estim.fit(data_tr.drop(columns=['id']), target)\n",
    "    utest_preds_4[name] = estim.predict_proba(data_test.drop(columns=['id']))[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = Y['5']\n",
    "for name, estim, data_tr, data_test in estims_data:\n",
    "    print(name)\n",
    "    ustacked_preds_5[name] = get_stack_preds(estim, data_tr.drop(columns=['id']), target, 10)\n",
    "    print(roc_auc_score(target, ustacked_preds_5[name]))\n",
    "    estim.fit(data_tr.drop(columns=['id']), target)\n",
    "    utest_preds_5[name] = estim.predict_proba(data_test.drop(columns=['id']))[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uds_1 = {}\n",
    "uds_1['ucl_1'] = ustacked_preds_1['xgb_1']\n",
    "uds_1['ucl_3'] = ustacked_preds_1['rf_1']\n",
    "uds_1['ucl_5'] = ustacked_preds_1['lr_1']\n",
    "uds_1['ucl_8'] = ustacked_preds_1['svm_r']\n",
    "uds_1['ucl_9'] = ustacked_preds_1['nn']\n",
    "uds_1_test = {}\n",
    "uds_1_test['ucl_1'] = utest_preds_1['xgb_1']\n",
    "uds_1_test['ucl_3'] = utest_preds_1['rf_1']\n",
    "uds_1_test['ucl_5'] = utest_preds_1['lr_1']\n",
    "uds_1_test['ucl_8'] = utest_preds_1['svm_r']\n",
    "uds_1_test['ucl_9'] = utest_preds_1['nn']\n",
    "uds_1_ = pd.DataFrame(uds_1)\n",
    "uds_1_test_ = pd.DataFrame(uds_1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uds_1 = {}\n",
    "uds_1['ucl_1'] = ustacked_preds_2['xgb_1']\n",
    "uds_1['ucl_3'] = ustacked_preds_2['rf_1']\n",
    "uds_1['ucl_5'] = ustacked_preds_2['lr_1']\n",
    "uds_1['ucl_8'] = ustacked_preds_2['svm_r']\n",
    "uds_1['ucl_9'] = ustacked_preds_2['nn']\n",
    "uds_1_test = {}\n",
    "uds_1_test['ucl_1'] = utest_preds_2['xgb_1']\n",
    "uds_1_test['ucl_3'] = utest_preds_2['rf_1']\n",
    "uds_1_test['ucl_5'] = utest_preds_2['lr_1']\n",
    "uds_1_test['ucl_8'] = utest_preds_2['svm_r']\n",
    "uds_1_test['ucl_9'] = utest_preds_2['nn']\n",
    "uds_2 = pd.DataFrame(uds_1)\n",
    "uds_2_test = pd.DataFrame(uds_1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uds_1 = {}\n",
    "uds_1['ucl_1'] = ustacked_preds_3['xgb_1']\n",
    "uds_1['ucl_3'] = ustacked_preds_3['rf_1']\n",
    "uds_1['ucl_5'] = ustacked_preds_3['lr_1']\n",
    "uds_1['ucl_8'] = ustacked_preds_3['svm_r']\n",
    "uds_1['ucl_9'] = ustacked_preds_3['nn']\n",
    "uds_1_test = {}\n",
    "uds_1_test['ucl_1'] = utest_preds_3['xgb_1']\n",
    "uds_1_test['ucl_3'] = utest_preds_3['rf_1']\n",
    "uds_1_test['ucl_5'] = utest_preds_3['lr_1']\n",
    "uds_1_test['ucl_8'] = utest_preds_3['svm_r']\n",
    "uds_1_test['ucl_9'] = utest_preds_3['nn']\n",
    "uds_3 = pd.DataFrame(uds_1)\n",
    "uds_3_test = pd.DataFrame(uds_1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uds_1 = {}\n",
    "uds_1['ucl_1'] = ustacked_preds_4['xgb_1']\n",
    "uds_1['ucl_3'] = ustacked_preds_4['rf_1']\n",
    "uds_1['ucl_5'] = ustacked_preds_4['lr_1']\n",
    "uds_1['ucl_8'] = ustacked_preds_4['svm_r']\n",
    "uds_1['ucl_9'] = ustacked_preds_4['nn']\n",
    "uds_1_test = {}\n",
    "uds_1_test['ucl_1'] = utest_preds_4['xgb_1']\n",
    "uds_1_test['ucl_3'] = utest_preds_4['rf_1']\n",
    "uds_1_test['ucl_5'] = utest_preds_4['lr_1']\n",
    "uds_1_test['ucl_8'] = utest_preds_4['svm_r']\n",
    "uds_1_test['ucl_9'] = utest_preds_4['nn']\n",
    "uds_4 = pd.DataFrame(uds_1)\n",
    "uds_4_test = pd.DataFrame(uds_1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uds_1 = {}\n",
    "uds_1['ucl_1'] = ustacked_preds_5['xgb_1']\n",
    "uds_1['ucl_3'] = ustacked_preds_5['rf_1']\n",
    "uds_1['ucl_5'] = ustacked_preds_5['lr_1']\n",
    "uds_1['ucl_8'] = ustacked_preds_5['svm_r']\n",
    "uds_1['ucl_9'] = ustacked_preds_5['nn']\n",
    "uds_1_test = {}\n",
    "uds_1_test['ucl_1'] = utest_preds_5['xgb_1']\n",
    "uds_1_test['ucl_3'] = utest_preds_5['rf_1']\n",
    "uds_1_test['ucl_5'] = utest_preds_5['lr_1']\n",
    "uds_1_test['ucl_8'] = utest_preds_5['svm_r']\n",
    "uds_1_test['ucl_9'] = utest_preds_5['nn']\n",
    "uds_5 = pd.DataFrame(uds_1)\n",
    "uds_5_test = pd.DataFrame(uds_1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging ALS and UMAP extractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_1_['id'] = X1.id\n",
    "uds_1_['id'] = X1.id\n",
    "ds_1_test_['id'] = X1_test.id\n",
    "uds_1_test_['id'] = X1_test.id\n",
    "lr = LogisticRegression(class_weight='balanced', C=2)\n",
    "lr.fit(ds_1_.merge(uds_1_, on='id').drop(columns=['id']), Y['1'])\n",
    "Y1 = lr.predict_proba(ds_1_test_.merge(uds_1_test_, on='id').drop(columns=['id']))[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_2['id'] = X1.id\n",
    "uds_2['id'] = X1.id\n",
    "ds_2_test['id'] = X1_test.id\n",
    "uds_2_test['id'] = X1_test.id\n",
    "lr = LogisticRegression(class_weight='balanced', C=2)\n",
    "lr.fit(ds_2.merge(uds_2, on='id').drop(columns=['id']), Y['2'])\n",
    "Y2 = lr.predict_proba(ds_2_test.merge(uds_2_test, on='id').drop(columns=['id']))[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_3['id'] = X1.id\n",
    "uds_3['id'] = X1.id\n",
    "\n",
    "ds_3_test['id'] = X1_test.id\n",
    "uds_3_test['id'] = X1_test.id\n",
    "lr = LogisticRegression(class_weight='balanced', C=2)\n",
    "lr.fit(ds_3.merge(uds_3, on='id').drop(columns=['id']), Y['3'])\n",
    "Y3 = lr.predict_proba(ds_3_test.merge(uds_3_test, on='id').drop(columns=['id']))[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_4['id'] = X1.id\n",
    "uds_4['id'] = X1.id\n",
    "ds_4_test['id'] = X1_test.id\n",
    "uds_4_test['id'] = X1_test.id\n",
    "lr = LogisticRegression(class_weight='balanced', C=2)\n",
    "lr.fit(ds_4.merge(uds_4, on='id').drop(columns=['id']), Y['4'])\n",
    "Y4 = lr.predict_proba(ds_4_test.merge(uds_4_test, on='id').drop(columns=['id']))[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_5['id'] = X1.id\n",
    "uds_5['id'] = X1.id\n",
    "ds_5_test['id'] = X1_test.id\n",
    "uds_5_test['id'] = X1_test.id\n",
    "lr = LogisticRegression(class_weight='balanced', C=2)\n",
    "lr.fit(ds_5.merge(uds_5, on='id').drop(columns=['id']), Y['5'])\n",
    "Y5 = lr.predict_proba(ds_5_test.merge(uds_5_test, on='id').drop(columns=['id']))[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "df['id'] = X1_test.id\n",
    "df['1'] = Y1\n",
    "df['2'] = Y2\n",
    "df['3'] = Y3\n",
    "df['4'] = Y4\n",
    "df['5'] = Y5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('final.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
